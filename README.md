# Projet-MLA

# Reproduction du mod√®le CamemBERT

Ce projet vise √† reproduire les r√©sultats exp√©rimentaux de l'article *CamemBERT: a Tasty French Language Model*. Il s'agit d'impl√©menter en TensorFlow ou PyTorch l'architecture propos√©e et de valider ses performances sur plusieurs t√¢ches NLP en utilisant un GPU.

---

## üìã **Objectifs du projet :**
- Impl√©menter l'architecture CamemBERT (bas√©e sur RoBERTa) pour le fran√ßais.
- Entra√Æner le mod√®le sur des corpus diversifi√©s (OSCAR).
- √âvaluer les performances sur des t√¢ches de NLP : POS tagging, parsing, NER, et NLI.
- Comparer les r√©sultats avec ceux de l'article original.

---

## üõ†Ô∏è **Pr√©requis :**
### **Environnement de d√©veloppement :**
- **Langages** : Python 3.8+
- **Frameworks** : TensorFlow / PyTorch
- **GPU** : CUDA / cuDNN install√©s pour l'acc√©l√©ration mat√©rielle

### **Biblioth√®ques n√©cessaires :**
```bash
pip install torch torchvision transformers
pip install tensorflow
pip install sentencepiece
```

---

## üìÇ **Structure du projet :**
```plaintext
CamemBERT-Reproduction/
‚îÇ
‚îú‚îÄ‚îÄ data/                  # Donn√©es pr√©trait√©es (OSCAR, CCNet, etc.)
‚îú‚îÄ‚îÄ models/                # Enregistrements des mod√®les entra√Æn√©s
‚îú‚îÄ‚îÄ scripts/               # Scripts d'entra√Ænement et d'√©valuation
‚îú‚îÄ‚îÄ notebooks/             # Analyse des r√©sultats et visualisations
‚îú‚îÄ‚îÄ report/                # Rapport LaTeX (6-8 pages)
‚îî‚îÄ‚îÄ README.md              # Documentation du projet
```

---

## üöÄ **√âtapes de reproduction :**

### 1. **Pr√©traitement des donn√©es :**
- T√©l√©charger le corpus OSCAR fran√ßais.
- Nettoyer et tokenizer avec **SentencePiece**.
  
### 2. **Impl√©mentation du mod√®le :**
- Reproduire l'architecture RoBERTa en utilisant TensorFlow ou PyTorch.
- Impl√©menter le masquage dynamique des mots entiers (Whole-Word Masking).

### 3. **Entra√Ænement :**
- Configurer l'objectif de **Masked Language Modeling (MLM)**.
- Lancer l'entra√Ænement sur un GPU avec des donn√©es de 4 Go et 138 Go :
  ```bash
  python train.py --data_path data/oscar_4gb.txt --epochs 10 --batch_size 32
  ```

### 4. **√âvaluation sur des t√¢ches aval :**
- Impl√©menter les t√¢ches POS tagging, NER, parsing, et NLI.
- Utiliser des benchmarks comme **Universal Dependencies (UD)** et **XNLI** :
  ```bash
  python evaluate.py --task pos_tagging --model_path models/camembert_base.pt
  ```

### 5. **Comparaison des r√©sultats :**
- Comparer les performances avec les mod√®les existants (**mBERT**, **XLM-R**).
- Analyser l'impact de la taille et de l'origine du corpus sur les r√©sultats.

### 6. **R√©daction du rapport LaTeX :**
- Pr√©senter l'architecture, les diff√©rences avec l'article, et les r√©sultats obtenus.
- Justifier les choix de conception et discuter les r√©sultats exp√©rimentaux.

### 7. **Cr√©ation de la vid√©o de pr√©sentation :**
- Enregistrer une vid√©o de 5 minutes expliquant le projet et les r√©sultats.
  - **Tous les participants doivent prendre la parole.**

---

## üìà **R√©sultats attendus :**
- Reproduction fid√®le des r√©sultats de l'article.
- Validation des performances sur diff√©rentes t√¢ches NLP.
- Comparaison critique des performances avec les mod√®les de r√©f√©rence.

---

## üí° **Ressources utiles :**
- [Article CamemBERT](https://arxiv.org/abs/1911.03894)
- [Corpus OSCAR](https://oscar-corpus.com/)
- [Documentation Hugging Face](https://huggingface.co/docs)
